{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7553e73",
   "metadata": {},
   "source": [
    "### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d449f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#Langsmith Tracking\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_PROJECT '] = os.getenv('LANGCHAIN_PROJECT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7812e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RAG PIPELINE\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "urL = \"https://docs.smith.langchain.com/administration/tutorials/manage_spend\"\n",
    "loader = WebBaseLoader(web_path = urL)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "vectorstore_db = FAISS.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf95b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The first metric tracks all traces that you send to LangSmith. The second tracks all traces that also have our Extended 400 Day Data Retention.\\nFor more details, see our data retention conceptual docs. Notice that these graphs look\\nidentical, which will come into play later in the tutorial.\\nLangSmith Traces usage is measured per workspace, because workspaces often represent development environments (as in our example),\\nor teams within an organization. As a LangSmith administrator, we want to understand spend granularly per each of these units. In\\nthis case where we just want to cut spend, we can focus on the environment responsible for the majority of costs first for the greatest savings.\\nnoteLangSmith's Usage Graph and Invoice use the term tenant_id to refer to a workspace ID. They are interchangeable.\\nIn the above image, the vast majority of usage is in the workspace with ID c27dd32c-7c80-4e8c-acde-bfcb67a90ab2. We can\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query From a vector store db\n",
    "query = \"LangSmith Traces usage is measured per workspace, because\"\n",
    "result = vectorstore_db.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f500bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangSmith Traces usage is measured per workspace. Workspaces typically represent development environments or teams within an organization.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrival Chain, Document chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model = \"gpt-4o\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"user\", \"\"\"Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\"\"\")\n",
    "])\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\" : \"LangSmith Traces usage is measured per workspace, because\",\n",
    "    \"context\" : [Document(page_content=\"LangSmith Traces usage is measured per workspace, because workspaces often represent development environments (as in our example), or teams within an organization.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5426b2",
   "metadata": {},
   "source": [
    "### Retriver -->\n",
    "Act as an interface of getting information from vector store db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a7eaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001D7C8493220>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='Answer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001D7FF7846D0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D7FF784850>, root_client=<openai.OpenAI object at 0x000001D7FF7A4A30>, root_async_client=<openai.AsyncOpenAI object at 0x000001D7FF784520>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver = vectorstore_db.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain = create_retrieval_chain(retriver, document_chain)\n",
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57cc4c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided context, LangSmith usage is measured per workspace, often corresponding to development environments or teams within an organization. The two metrics tracked by LangSmith are:\\n\\n1. **LangSmith Traces (Base Charge)**\\n2. **LangSmith Traces (Extended Data Retention Upgrades)**\\n\\nThe usage is detailed in the Usage Graph, and the monetary spend related to this usage can be understood via Invoices. Usage and billing are broken down by \"tenant_id,\" which is another term for Workspace ID. This allows administrators to track spending per workspace to help manage costs, especially when certain workspaces, like the one with ID `c27dd32c-7c80-4e8c-acde-bfcb67a90ab2`, contribute significantly to the overall spend.\\n\\nFor optimization, understanding current usage is the first step, utilizing both the Usage Graph and the invoices to get a clear view of costs and consumption.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting responce from llm\n",
    "response = retrieval_chain.invoke({\"input\": \"LangSmith Traces usage is measured per workspace, because\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'LangSmith Traces usage is measured per workspace, because',\n",
       " 'context': [Document(id='65c21d4e-42a8-4e0c-8622-30e9df93dbee', metadata={'source': 'https://docs.smith.langchain.com/administration/tutorials/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}, page_content=\"The first metric tracks all traces that you send to LangSmith. The second tracks all traces that also have our Extended 400 Day Data Retention.\\nFor more details, see our data retention conceptual docs. Notice that these graphs look\\nidentical, which will come into play later in the tutorial.\\nLangSmith Traces usage is measured per workspace, because workspaces often represent development environments (as in our example),\\nor teams within an organization. As a LangSmith administrator, we want to understand spend granularly per each of these units. In\\nthis case where we just want to cut spend, we can focus on the environment responsible for the majority of costs first for the greatest savings.\\nnoteLangSmith's Usage Graph and Invoice use the term tenant_id to refer to a workspace ID. They are interchangeable.\\nIn the above image, the vast majority of usage is in the workspace with ID c27dd32c-7c80-4e8c-acde-bfcb67a90ab2. We can\"),\n",
       "  Document(id='c7771652-6ef5-4ed5-91b5-34ab5f74b05d', metadata={'source': 'https://docs.smith.langchain.com/administration/tutorials/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}, page_content='your use case with LangSmith. For example, if you run evals as part of CI/CD in dev or staging, you may\\nwant to be more liberal with your usage limits to avoid test failures.\\nNow that our limits are set, we can see that LangSmith shows a maximum spend estimate across all workspaces:'),\n",
       "  Document(id='bc5e83f9-8933-4586-ad90-b4281f95b5f4', metadata={'source': 'https://docs.smith.langchain.com/administration/tutorials/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}, page_content='Understand your current usage\\u200b\\nThe first step of any optimization process is to understand current usage. LangSmith gives two ways to do this: Usage Graph\\nand Invoices.\\nUsage Graph\\u200b\\nThe usage graph lets us examine how much of each usage based pricing metric we have consumed lately. It does not directly show\\nspend (which we will see later on our draft invoice).\\nWe can navigate to the Usage Graph under Settings -> Usage and Billing -> Usage Graph.\\n\\nWe see in the graph above that there are two usage metrics that LangSmith charges for:\\n\\nLangSmith Traces (Base Charge)\\nLangSmith Traces (Extended Data Retention Upgrades).'),\n",
       "  Document(id='47f1c5a8-0783-414f-b9c1-e59884af2773', metadata={'source': 'https://docs.smith.langchain.com/administration/tutorials/manage_spend', 'title': 'Optimize tracing spend on LangSmith | ü¶úÔ∏èüõ†Ô∏è LangSmith', 'description': 'Before diving into this content, it might be helpful to read the following:', 'language': 'en'}, page_content='Invoices\\u200b\\nWe understand what usage looks like in terms of traces, but we now need to translate that into spend. To do so,\\nwe head to the Invoices tab. The first invoice that will appear on screen is a draft of your current month\\'s\\ninvoice, which shows your running spend thus far this month.\\n\\nIn the above GIF, we see that the charges for LangSmith Traces are broken up by \"tenant_id\" (i.e. Workspace ID), meaning we can track tracing spend\\non each of our workspaces. In the first few days of June, the vast majority of the total spend of ~$2,000 is in our production\\nworkspace. Further, the majority of spend in that workspace was on extended data retention trace upgrades.\\nThese upgrades occur for two reasons:\\n\\nYou use extended data retention tracing, meaning that, by default, your traces are retained for 400 days\\nYou use base data retention tracing, and use a feature that automatically extends the data retention of a trace (see our Auto-Upgrade conceptual docs)')],\n",
       " 'answer': 'According to the provided context, LangSmith usage is measured per workspace, often corresponding to development environments or teams within an organization. The two metrics tracked by LangSmith are:\\n\\n1. **LangSmith Traces (Base Charge)**\\n2. **LangSmith Traces (Extended Data Retention Upgrades)**\\n\\nThe usage is detailed in the Usage Graph, and the monetary spend related to this usage can be understood via Invoices. Usage and billing are broken down by \"tenant_id,\" which is another term for Workspace ID. This allows administrators to track spending per workspace to help manage costs, especially when certain workspaces, like the one with ID `c27dd32c-7c80-4e8c-acde-bfcb67a90ab2`, contribute significantly to the overall spend.\\n\\nFor optimization, understanding current usage is the first step, utilizing both the Usage Graph and the invoices to get a clear view of costs and consumption.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c826d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
